{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Demo\n",
    "\n",
    "Sample functionality for creating tables, inserting data and running similarity search with OgbujiPT.\n",
    "\n",
    "Notes:\n",
    "- `pip install jupyter` if notebook is not running\n",
    "\n",
    "This notebook will attempt to access a database named `PGv` at `sofola:5432`, using the username `oori` and password `example`. If you have a different setup, you can change the connection string in the first cell."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = 'PGv'\n",
    "HOST = 'sofola'\n",
    "PORT = 5432\n",
    "USER = 'oori'\n",
    "PASSWORD = 'example'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "\n",
    "from ogbujipt.embedding.pgvector import PGvectorHelper\n",
    "\n",
    "from sentence_transformers     import SentenceTransformer\n",
    "\n",
    "e_model = SentenceTransformer('all-MiniLM-L6-v2')  # Load the embedding model\n",
    "\n",
    "pacer_copypasta = [  # Demo data\n",
    "    'The FitnessGramâ„¢ Pacer Test is a multistage aerobic capacity test that progressively gets more difficult as it continues.', \n",
    "    'The 20 meter pacer test will begin in 30 seconds. Line up at the start.', \n",
    "    'The running speed starts slowly, but gets faster each minute after you hear this signal.', \n",
    "    '[beep] A single lap should be completed each time you hear this sound.', \n",
    "    '[ding] Remember to run in a straight line, and run as long as possible.', \n",
    "    'The second time you fail to complete a lap before the sound, your test is over.', \n",
    "    'The test will begin on the word start. On your mark, get ready, start.'\n",
    "]\n",
    "\n",
    "\n",
    "abbott_and_costello = [\n",
    "    {'role': 'system', 'content': 'The user is considering becoming a ballplayer. The assistant wants to make sure he knows what he\\'s getting into.'},\n",
    "    {'role': 'assistant', 'content': 'Strange as it may seem, they give ball players nowadays very peculiar names.'},\n",
    "    {'role': 'user', 'content': 'Funny names?'},\n",
    "    {'role': 'assistant', 'content': 'Nicknames, nicknames. Now, on the St. Louis team we have Who\\'s on first, What\\'s on second, I Don\\'t Know is on third--'},\n",
    "    {'role': 'user', 'content': 'That\\'s what I want to find out. I want you to tell me the names of the fellows on the St. Louis team.'},\n",
    "    {'role': 'assistant', 'content': \"I'm telling you. Who is on first. What's on second. I Don't Know's on third--\"},\n",
    "    {'role': 'user', 'content': \"You know the fellows' names?\"},\n",
    "    {'role': 'assistant', 'content': 'Yes.'},\n",
    "    {'role': 'user', 'content': \"Well, then who's playing first?\"},\n",
    "    {'role': 'assistant', 'content': 'Yes.'},\n",
    "    {'role': 'user', 'content': \"I mean the fellow's name on first base.\"},\n",
    "    {'role': 'assistant', 'content': 'Who.'},\n",
    "    {'role': 'user', 'content': \"The fellow playin' first base.\"},\n",
    "    {'role': 'assistant', 'content': 'Who.'},\n",
    "    {'role': 'user', 'content': \"The guy on first base.\"},\n",
    "    {'role': 'assistant', 'content': 'Who is on first.'},\n",
    "    {'role': 'user', 'content': \"Well, what are you askin' me for?\"},\n",
    "    {'role': 'assistant', 'content': \"I'm not asking you--I'm telling you. Who is on first.\"},\n",
    "    {'role': 'user', 'content': \"I'm asking you--who's on first?\"},\n",
    "    {'role': 'assistant', 'content': 'That\\'s the man\\'s name.'},\n",
    "    {'role': 'user', 'content': \"That's who's name?\"},\n",
    "    {'role': 'assistant', 'content': 'Yes.'},\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating database connections...\n",
      "Connected to database.\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating database connections...\")\n",
    "# Create a table for document (chunks)\n",
    "pacerDB = await PGvectorHelper.from_conn_params(\n",
    "    embedding_model=e_model, \n",
    "    table_name='pacer',\n",
    "    user=USER,\n",
    "    password=PASSWORD,\n",
    "    db_name=DB_NAME,\n",
    "    host=HOST,\n",
    "    port=int(PORT)\n",
    ")\n",
    "\n",
    "# Create a table for chatlogs\n",
    "baseballDB = await PGvectorHelper.from_conn_params(\n",
    "    embedding_model=e_model, \n",
    "    table_name='baseball',\n",
    "    user=USER,\n",
    "    password=PASSWORD,\n",
    "    db_name=DB_NAME,\n",
    "    host=HOST,\n",
    "    port=int(PORT)\n",
    ")\n",
    "print(\"Connected to database.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGvector extension created and loaded.\n",
      "Tables dropped.\n",
      "Tables created.\n"
     ]
    }
   ],
   "source": [
    "# Ensuring that the vector extension is installed\n",
    "await pacerDB.conn.execute('''CREATE EXTENSION IF NOT EXISTS vector;''')\n",
    "await baseballDB.conn.execute('''CREATE EXTENSION IF NOT EXISTS vector;''')\n",
    "print(\"PGvector extension created and loaded.\")\n",
    "\n",
    "# Drop the table if one is found\n",
    "await pacerDB.drop_table()\n",
    "await baseballDB.drop_table()\n",
    "print(\"Tables dropped.\")\n",
    "\n",
    "# Creating a new table\n",
    "await pacerDB.create_doc_table()\n",
    "await baseballDB.create_chatlog_table()\n",
    "print(\"Tables created.\")\n",
    "\n",
    "await baseballDB.conn.set_type_codec(\n",
    "    'JSON',\n",
    "    encoder=json.dumps,\n",
    "    decoder=json.loads,\n",
    "    schema='pg_catalog'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, text in enumerate(pacer_copypasta):   # For each line in the copypasta\n",
    "    await pacerDB.insert_doc(                    # Insert the line into the table\n",
    "        content=text,                            # The text to be embedded\n",
    "        permission='public',                     # Permission metadata for access control\n",
    "        title=f'Pacer Copypasta line {index}',   # Title metadata\n",
    "        page_numbers=[1, 2, 3],                  # Page number metadata\n",
    "        tags=['fitness', 'pacer', 'copypasta'],  # Tag metadata\n",
    "    )\n",
    "\n",
    "history_key = str(uuid.uuid4())                  # Generate a key for the chatlog\n",
    "for line in abbott_and_costello:                 # For each line of dialog in the script\n",
    "    await baseballDB.insert_message(             # Insert the message into the table\n",
    "        history_key=history_key,                 # The key for the chatlog\n",
    "        role=line['role'],\n",
    "        content=line['content'],\n",
    "        metadata={'genre': 'comedy', 'year': 1938}\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3  # Setting number of rows to return when searching\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "def print_doc_results(results):  # Helper function to print document results\n",
    "    print(f'RAW RETURN:')  \n",
    "    pprint(results)                                                               # Print the raw results\n",
    "    print(f'\\nRETURNED TITLE:\\n\"{results[0][\"title\"]}\"')                          # Print the title of the first result\n",
    "    print(f'RETURNED CONTENT:\\n\"{results[0][\"content\"]}\"')                        # Print the content of the first result\n",
    "    print(f'RETURNED COSINE SIMILARITY:\\n{results[0][\"cosine_similarity\"]:.2f}')  # Print the cosine similarity of the first result\n",
    "\n",
    "\n",
    "def print_chatlog_results(results):  # Helper function to print chatlog results\n",
    "    print(f'RAW RETURN:')  \n",
    "    pprint(results)                                                               # Print the raw results\n",
    "    print(f'\\nRETURNED INDEX:\\n\"{results[0][\"index\"]}\"')                          # Print the index of the first result\n",
    "    print(f'RETURNED MESSAGE:\\n{results[0][\"role\"]}: {results[0][\"content\"]}')    # Print the message of the first result\n",
    "    print(f'RETURNED COSINE SIMILARITY:\\n{results[0][\"cosine_similarity\"]:.2f}')  # Print the cosine similarity of the first result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching the table with a perfect match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Searching data using search string:\n",
      "\"[beep] A single lap should be completed each time you hear this sound.\"\n",
      "\n",
      "RAW RETURN:\n",
      "[<Record cosine_similarity=0.0 title='Pacer Copypasta line 3' content='[beep] A single lap should be completed each time you hear this sound.' permission='public' page_numbers=[1, 2, 3] tags=['fitness', 'pacer', 'copypasta']>,\n",
      " <Record cosine_similarity=0.31445924384770496 title='Pacer Copypasta line 5' content='The second time you fail to complete a lap before the sound, your test is over.' permission='public' page_numbers=[1, 2, 3] tags=['fitness', 'pacer', 'copypasta']>,\n",
      " <Record cosine_similarity=0.634082588486436 title='Pacer Copypasta line 2' content='The running speed starts slowly, but gets faster each minute after you hear this signal.' permission='public' page_numbers=[1, 2, 3] tags=['fitness', 'pacer', 'copypasta']>]\n",
      "\n",
      "RETURNED TITLE:\n",
      "\"Pacer Copypasta line 3\"\n",
      "RETURNED CONTENT:\n",
      "\"[beep] A single lap should be completed each time you hear this sound.\"\n",
      "RETURNED COSINE SIMILARITY:\n",
      "0.00\n"
     ]
    }
   ],
   "source": [
    "search_string = '[beep] A single lap should be completed each time you hear this sound.'\n",
    "print(f'Semantic Searching data using search string:\\n\"{search_string}\"\\n')\n",
    "\n",
    "sim_search = await pacerDB.search_doc_table(\n",
    "    query_string=search_string,\n",
    "    limit=k\n",
    ")\n",
    "\n",
    "print_doc_results(sim_search)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching the table with a partial match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Searching data using search string:\n",
      "\"straight\"\n",
      "\n",
      "RAW RETURN:\n",
      "[<Record cosine_similarity=0.7157614573027005 title='Pacer Copypasta line 4' content='[ding] Remember to run in a straight line, and run as long as possible.' permission='public' page_numbers=[1, 2, 3] tags=['fitness', 'pacer', 'copypasta']>,\n",
      " <Record cosine_similarity=0.8959717930563745 title='Pacer Copypasta line 6' content='The test will begin on the word start. On your mark, get ready, start.' permission='public' page_numbers=[1, 2, 3] tags=['fitness', 'pacer', 'copypasta']>,\n",
      " <Record cosine_similarity=0.9200870391648666 title='Pacer Copypasta line 2' content='The running speed starts slowly, but gets faster each minute after you hear this signal.' permission='public' page_numbers=[1, 2, 3] tags=['fitness', 'pacer', 'copypasta']>]\n",
      "\n",
      "RETURNED TITLE:\n",
      "\"Pacer Copypasta line 4\"\n",
      "RETURNED CONTENT:\n",
      "\"[ding] Remember to run in a straight line, and run as long as possible.\"\n",
      "RETURNED COSINE SIMILARITY:\n",
      "0.72\n"
     ]
    }
   ],
   "source": [
    "search_string = 'straight'\n",
    "print(f'Semantic Searching data using search string:\\n\"{search_string}\"\\n')\n",
    "\n",
    "sim_search = await pacerDB.search_doc_table(\n",
    "    query_string=search_string,\n",
    "    limit=k\n",
    ")\n",
    "\n",
    "print_results(sim_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Searching data using search string:\n",
      "\"The guy on first base.\"\n",
      "\n",
      "RAW RETURN:\n",
      "[<Record cosine_similarity=0.0 index=15 role=1 content='The guy on first base.' metadata_json={'genre': 'comedy', 'year': 1938}>,\n",
      " <Record cosine_similarity=0.21688772288967784 index=13 role=1 content=\"The fellow playin' first base.\" metadata_json={'genre': 'comedy', 'year': 1938}>,\n",
      " <Record cosine_similarity=0.23151054288415174 index=11 role=1 content=\"I mean the fellow's name on first base.\" metadata_json={'genre': 'comedy', 'year': 1938}>]\n",
      "\n",
      "RETURNED INDEX:\n",
      "\"15\"\n",
      "RETURNED MESSAGE:\n",
      "1: The guy on first base.\n",
      "RETURNED COSINE SIMILARITY:\n",
      "0.00\n"
     ]
    }
   ],
   "source": [
    "search_string = 'The guy on first base.'\n",
    "print(f'Semantic Searching data using search string:\\n\"{search_string}\"\\n')\n",
    "\n",
    "sim_search = await baseballDB.search_chatlog(\n",
    "    history_key=history_key,\n",
    "    query_string=search_string,\n",
    "    limit=k\n",
    ")\n",
    "\n",
    "print_chatlog_results(sim_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Searching data using search string:\n",
      "\"nickname\"\n",
      "\n",
      "RAW RETURN:\n",
      "[<Record cosine_similarity=0.4910637432970839 index=4 role=2 content=\"Nicknames, nicknames. Now, on the St. Louis team we have Who's on first, What's on second, I Don't Know is on third--\" metadata_json={'genre': 'comedy', 'year': 1938}>,\n",
      " <Record cosine_similarity=0.561316881258301 index=3 role=1 content='Funny names?' metadata_json={'genre': 'comedy', 'year': 1938}>,\n",
      " <Record cosine_similarity=0.5729953094121991 index=20 role=2 content=\"That's the man's name.\" metadata_json={'genre': 'comedy', 'year': 1938}>]\n",
      "\n",
      "RETURNED INDEX:\n",
      "\"4\"\n",
      "RETURNED MESSAGE:\n",
      "2: Nicknames, nicknames. Now, on the St. Louis team we have Who's on first, What's on second, I Don't Know is on third--\n",
      "RETURNED COSINE SIMILARITY:\n",
      "0.49\n"
     ]
    }
   ],
   "source": [
    "search_string = 'nickname'\n",
    "print(f'Semantic Searching data using search string:\\n\"{search_string}\"\\n')\n",
    "\n",
    "sim_search = await baseballDB.search_chatlog(\n",
    "    history_key=history_key,\n",
    "    query_string=search_string,\n",
    "    limit=k\n",
    ")\n",
    "\n",
    "print_chatlog_results(sim_search)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
