{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Hybrid Search with OgbujiPT\n",
    "\n",
    "Interactive exploration of **hybrid search** combining:\n",
    "- **Dense vector search** (semantic similarity via embeddings)\n",
    "- **Sparse BM25 search** (keyword-based retrieval)\n",
    "- **Reciprocal Rank Fusion** (RRF) to merge results\n",
    "\n",
    "## Prerequisites & Running\n",
    "\n",
    "1. PostgreSQL with pgvector running (see README.md for Docker setup)\n",
    "2. Required packages:\n",
    "```bash\n",
    "uv pip install \"ogbujipt>=0.10.0\"\n",
    "uv pip install jupyter\n",
    "```\n",
    "\n",
    "Run the notebook:\n",
    "\n",
    "```bash\n",
    "jupyter notebook hybrid_search.ipynb\n",
    "```\n",
    "\n",
    "## Why Hybrid Search?\n",
    "\n",
    "Different search methods excel at different tasks:\n",
    "\n",
    "| Method | Strengths | Weaknesses |\n",
    "|--------|-----------|------------|\n",
    "| **Dense vectors** | Semantic meaning, synonyms, concepts | Misses exact terminology, names |\n",
    "| **Sparse BM25** | Exact keywords, names, terminology | Misses semantic similarity |\n",
    "| **Hybrid (RRF)** | Best of both! | Slightly more complex |\n",
    "\n",
    "**Example**: Searching for \\\"ML algorithms\\\"\n",
    "- Dense finds: \\\"machine learning techniques\\\", \\\"neural networks\\\"\n",
    "- Sparse finds: \\\"ML\\\", \\\"algorithms\\\", \\\"random forest algorithm\\\"\n",
    "- Hybrid: Ranks results that match both semantic + keyword criteria highest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from typing import AsyncIterator\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from ogbujipt.store.postgres import DataDB\n",
    "from ogbujipt.retrieval import BM25Search, HybridSearch, SimpleDenseSearch\n",
    "from ogbujipt.memory.base import SearchResult\n",
    "\n",
    "# Database connection parameters (adjust if needed)\n",
    "PG_DB_NAME = os.environ.get('PG_DB_NAME', 'hybrid_demo')\n",
    "PG_DB_HOST = os.environ.get('PG_DB_HOST', 'localhost')\n",
    "PG_DB_PORT = int(os.environ.get('PG_DB_PORT', '5432'))\n",
    "PG_DB_USER = os.environ.get('PG_DB_USER', 'demo_user')\n",
    "PG_DB_PASSWORD = os.environ.get('PG_DB_PASSWORD', 'demo_pass_2025')\n",
    "\n",
    "# Load embedding model (this may take a minute on first run)\n",
    "print('Loading embedding model...')\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print('‚úì Model loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Knowledge Base\n",
    "\n",
    "Let's create a small knowledge base about machine learning and programming topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample documents covering various ML/programming topics\n",
    "knowledge_base = [\n",
    "    {'content': 'Machine learning (ML) is a subset of artificial intelligence that enables systems to learn from data without explicit programming.', 'metadata': {'topic': 'ML basics', 'difficulty': 'beginner'}},\n",
    "    {'content': 'Neural networks are computing systems inspired by biological neural networks. They consist of layers of interconnected nodes.', 'metadata': {'topic': 'neural networks', 'difficulty': 'intermediate'}},\n",
    "    {'content': 'Random forest is an ensemble learning algorithm that constructs multiple decision trees during training.', 'metadata': {'topic': 'algorithms', 'difficulty': 'intermediate'}},\n",
    "    {'content': 'Python is a high-level programming language widely used for ML development due to libraries like scikit-learn, TensorFlow, and PyTorch.', 'metadata': {'topic': 'programming', 'difficulty': 'beginner'}},\n",
    "    {'content': 'Gradient descent is an optimization algorithm used to minimize loss functions in ML by iteratively moving toward the minimum.', 'metadata': {'topic': 'optimization', 'difficulty': 'intermediate'}},\n",
    "    {'content': 'Supervised learning uses labeled training data to learn mappings from inputs to outputs. Examples include classification and regression.', 'metadata': {'topic': 'ML basics', 'difficulty': 'beginner'}},\n",
    "    {'content': 'Convolutional Neural Networks (CNNs) are specialized for processing grid-like data such as images. They use convolutional layers.', 'metadata': {'topic': 'deep learning', 'difficulty': 'advanced'}},\n",
    "    {'content': 'K-means clustering is an unsupervised learning algorithm that partitions data into K clusters based on feature similarity.', 'metadata': {'topic': 'clustering', 'difficulty': 'beginner'}},\n",
    "    {'content': 'Transfer learning leverages pre-trained models on new tasks, reducing training time and data requirements significantly.', 'metadata': {'topic': 'deep learning', 'difficulty': 'advanced'}},\n",
    "    {'content': 'The backpropagation algorithm computes gradients of the loss function with respect to network weights using the chain rule.', 'metadata': {'topic': 'neural networks', 'difficulty': 'advanced'}},\n",
    "    {'content': 'Support Vector Machines (SVMs) find optimal hyperplanes that maximize the margin between different classes in the feature space.', 'metadata': {'topic': 'algorithms', 'difficulty': 'intermediate'}},\n",
    "    {'content': 'Overfitting occurs when a model learns training data too well, including noise, resulting in poor generalization to new data.', 'metadata': {'topic': 'ML basics', 'difficulty': 'beginner'}},\n",
    "]\n",
    "\n",
    "print(f'Knowledge base contains {len(knowledge_base)} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PostgreSQL and create table\n",
    "kb_db = await DataDB.from_conn_params(\n",
    "    embedding_model=embedding_model,\n",
    "    table_name='ml_knowledge',\n",
    "    db_name=PG_DB_NAME,\n",
    "    host=PG_DB_HOST,\n",
    "    port=PG_DB_PORT,\n",
    "    user=PG_DB_USER,\n",
    "    password=PG_DB_PASSWORD,\n",
    "    itypes=['vector'],  # Create HNSW index for fast vector search\n",
    "    ifuncs=['cosine']\n",
    ")\n",
    "\n",
    "print('‚úì Connected to PostgreSQL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Table and Insert Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop existing table if present (for clean demo)\n",
    "if await kb_db.table_exists():\n",
    "    await kb_db.drop_table()\n",
    "    print('‚úì Dropped existing table')\n",
    "\n",
    "# Create fresh table\n",
    "await kb_db.create_table()\n",
    "print('‚úì Created table: ml_knowledge')\n",
    "\n",
    "# Insert all documents\n",
    "await kb_db.insert_many([\n",
    "    (doc['content'], doc['metadata']) \n",
    "    for doc in knowledge_base\n",
    "])\n",
    "\n",
    "doc_count = await kb_db.count_items()\n",
    "print(f'‚úì Inserted {doc_count} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Dense Vector Search Only\n",
    "\n",
    "First, let's try traditional dense vector search (semantic similarity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What are ML algorithms?'\n",
    "\n",
    "print(f'Query: \"{query}\"\\n')\n",
    "print('=' * 60)\n",
    "print('DENSE VECTOR SEARCH (semantic similarity)')\n",
    "print('=' * 60)\n",
    "\n",
    "dense_results = []\n",
    "async for result in kb_db.search(query=query, limit=5):\n",
    "    dense_results.append(result)\n",
    "\n",
    "for i, result in enumerate(dense_results, 1):\n",
    "    print(f'\\n{i}. Score: {result.score:.3f}')\n",
    "    print(f'   {result.content}')\n",
    "    print(f'   [Topic: {result.metadata.get(\"topic\", \"unknown\")}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Sparse BM25 Search Only\n",
    "\n",
    "Now let's try BM25 sparse retrieval (keyword-based)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Query: \"{query}\"\\n')\n",
    "print('=' * 60)\n",
    "print('SPARSE BM25 SEARCH (keyword-based)')\n",
    "print('=' * 60)\n",
    "\n",
    "# Initialize BM25 search\n",
    "bm25 = BM25Search(\n",
    "    k1=1.5,      # Term frequency saturation\n",
    "    b=0.75,      # Document length normalization\n",
    "    epsilon=0.25 # IDF floor\n",
    ")\n",
    "\n",
    "# Execute search\n",
    "sparse_results = []\n",
    "async for result in bm25.execute(query=query, backends=[kb_db], limit=5):\n",
    "    sparse_results.append(result)\n",
    "\n",
    "for i, result in enumerate(sparse_results, 1):\n",
    "    print(f'\\n{i}. Score: {result.score:.3f}')\n",
    "    print(f'   {result.content}')\n",
    "    print(f'   [Topic: {result.metadata.get(\"topic\", \"unknown\")}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Hybrid Search (Dense + Sparse with RRF)\n",
    "\n",
    "Now let's combine both approaches using Reciprocal Rank Fusion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Query: \"{query}\"\\n')\n",
    "print('=' * 60)\n",
    "print('HYBRID SEARCH (Dense + Sparse with RRF)')\n",
    "print('=' * 60)\n",
    "\n",
    "# Initialize hybrid search with both strategies\n",
    "hybrid = HybridSearch(\n",
    "    strategies=[\n",
    "        SimpleDenseSearch(),  # Dense vector search\n",
    "        BM25Search()          # Sparse BM25 search\n",
    "    ],\n",
    "    k=60  # RRF constant\n",
    ")\n",
    "\n",
    "# Execute hybrid search\n",
    "hybrid_results = []\n",
    "async for result in hybrid.execute(query=query, backends=[kb_db], limit=5):\n",
    "    hybrid_results.append(result)\n",
    "\n",
    "for i, result in enumerate(hybrid_results, 1):\n",
    "    print(f'\\n{i}. Score: {result.score:.3f}')\n",
    "    print(f'   {result.content}')\n",
    "    print(f'   [Topic: {result.metadata.get(\"topic\", \"unknown\")}]')\n",
    "    print(f'   [Sources: {result.source}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Query with Exact Terminology\n",
    "\n",
    "Let's try a query where exact keywords matter (\\\"CNN\\\" for Convolutional Neural Network)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_terminology = 'Tell me about CNNs and image processing'\n",
    "\n",
    "print(f'Query: \"{query_terminology}\"\\n')\n",
    "print('This query tests how well each method handles abbreviations (CNN)\\n')\n",
    "\n",
    "# Dense search\n",
    "print('\\n' + '='*60)\n",
    "print('DENSE (might miss \"CNN\" abbreviation)')\n",
    "print('='*60)\n",
    "dense_results = []\n",
    "async for r in kb_db.search(query=query_terminology, limit=3):\n",
    "    dense_results.append(r)\n",
    "for i, r in enumerate(dense_results, 1):\n",
    "    print(f'{i}. [{r.score:.3f}] {r.content[:80]}...')\n",
    "\n",
    "# Sparse search\n",
    "print('\\n' + '='*60)\n",
    "print('SPARSE (catches \"CNN\" keyword)')\n",
    "print('='*60)\n",
    "sparse_results = []\n",
    "async for r in bm25.execute(query=query_terminology, backends=[kb_db], limit=3):\n",
    "    sparse_results.append(r)\n",
    "for i, r in enumerate(sparse_results, 1):\n",
    "    print(f'{i}. [{r.score:.3f}] {r.content[:80]}...')\n",
    "\n",
    "# Hybrid search\n",
    "print('\\n' + '='*60)\n",
    "print('HYBRID (best of both!)')\n",
    "print('='*60)\n",
    "hybrid_results = []\n",
    "async for r in hybrid.execute(query=query_terminology, backends=[kb_db], limit=3):\n",
    "    hybrid_results.append(r)\n",
    "for i, r in enumerate(hybrid_results, 1):\n",
    "    print(f'{i}. [{r.score:.3f}] {r.content[:80]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment: Tuning BM25 Parameters\n",
    "\n",
    "BM25 has parameters you can tune. Let's experiment with different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_test = 'optimization algorithm gradient'\n",
    "\n",
    "print(f'Query: \"{query_test}\"\\n')\n",
    "print('Testing different k1 values (term frequency saturation):\\n')\n",
    "\n",
    "# Test different k1 values\n",
    "for k1_val in [1.2, 1.5, 2.0]:\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'BM25 with k1={k1_val}, b=0.75')\n",
    "    print('='*60)\n",
    "    \n",
    "    bm25_tuned = BM25Search(k1=k1_val, b=0.75)\n",
    "    \n",
    "    results = []\n",
    "    async for r in bm25_tuned.execute(query=query_test, backends=[kb_db], limit=3):\n",
    "        results.append(r)\n",
    "    \n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f'{i}. [{r.score:.3f}] {r.content[:70]}...')\n",
    "\n",
    "print('\\nüí° Tip: Higher k1 = more weight on term frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding RRF Scores\n",
    "\n",
    "Hybrid search includes metadata showing how results were ranked by each strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_rrf = 'neural network training'\n",
    "\n",
    "print(f'Query: \"{query_rrf}\"\\n')\n",
    "print('='*60)\n",
    "print('RRF Ranking Details')\n",
    "print('='*60)\n",
    "\n",
    "hybrid_detailed = []\n",
    "async for r in hybrid.execute(query=query_rrf, backends=[kb_db], limit=3):\n",
    "    hybrid_detailed.append(r)\n",
    "\n",
    "for i, r in enumerate(hybrid_detailed, 1):\n",
    "    print(f'\\n{i}. Final RRF Score: {r.score:.3f}')\n",
    "    print(f'   {r.content[:100]}...')\n",
    "    \n",
    "    # Show individual strategy ranks\n",
    "    if 'rrf_ranks' in r.metadata:\n",
    "        print('   Individual strategy rankings:')\n",
    "        for strategy, rank, score in r.metadata['rrf_ranks']:\n",
    "            print(f'     ‚Ä¢ {strategy}: rank #{rank}, score {score:.3f}')\n",
    "\n",
    "print('\\nüí° RRF formula: score = sum(1 / (k + rank)) for each strategy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Your Own Query!\n",
    "\n",
    "Modify the query below and see how different methods perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è Edit this query to test different searches!\n",
    "my_query = 'supervised classification'\n",
    "\n",
    "print(f'Your query: \"{my_query}\"\\n')\n",
    "\n",
    "# Run all three methods\n",
    "print('DENSE:')\n",
    "count = 0\n",
    "async for r in kb_db.search(query=my_query, limit=2):\n",
    "    count += 1\n",
    "    print(f'  {count}. [{r.score:.3f}] {r.content[:60]}...')\n",
    "\n",
    "print('\\nSPARSE:')\n",
    "count = 0\n",
    "async for r in bm25.execute(query=my_query, backends=[kb_db], limit=2):\n",
    "    count += 1\n",
    "    print(f'  {count}. [{r.score:.3f}] {r.content[:60]}...')\n",
    "\n",
    "print('\\nHYBRID:')\n",
    "count = 0\n",
    "async for r in hybrid.execute(query=my_query, backends=[kb_db], limit=2):\n",
    "    count += 1\n",
    "    print(f'  {count}. [{r.score:.3f}] {r.content[:60]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the demo table\n",
    "await kb_db.drop_table()\n",
    "print('Dropped demo table')\n",
    "print('\\nDemo complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Dense search** excels at semantic similarity but can miss exact terminology\n",
    "2. **Sparse BM25** excels at keyword matching but misses semantic relationships\n",
    "3. **Hybrid RRF** combines both, typically outperforming either alone\n",
    "4. **Tune BM25** parameters (k1, b) based on your corpus and query patterns\n",
    "5. **Inspect RRF metadata** to understand how results are ranked\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try the `chat_with_hybrid_kb.py` demo for a full conversational AI application\n",
    "- Experiment with your own documents and queries\n",
    "- Explore `SparseDB` for storing sparse vectors directly\n",
    "- Combine with reranking models for even better results\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [BM25 Algorithm](https://en.wikipedia.org/wiki/Okapi_BM25)\n",
    "- [Reciprocal Rank Fusion Paper](http://www.cs.uwaterloo.ca/~jimmylin/publications/Cormack_etal_SIGIR2009.pdf)\n",
    "- [pgvector Documentation](https://github.com/pgvector/pgvector)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
